# app.py

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from bs4 import BeautifulSoup
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from ydata_profiling import ProfileReport
import time

st.set_page_config(
    page_title='An√°lise de previs√£o de Renda',
    layout='centered',
    page_icon='üí∞',
    initial_sidebar_state='expanded',
    menu_items={'About': 'Projeto de An√°lise de Previs√£o de Renda desenvolvido por Antonio Moura Jr durante o curso de Data Science da EBAC.'}
)


@st.cache_data # Cache para n√£o recarregar os datos a cada intera√ß√£o
def carregar_dados():
    df = pd.read_csv('./input/previsao_de_renda.csv')
    return df

@st.cache_data
def preprocessar_dados(_df):
    # Pr√©-processamento dos dados
    df_encoded = _df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente']).copy()
    df_encoded.loc[df_encoded['tipo_renda'] == 'Pensionista', 'tempo_emprego'] = \
        df_encoded.loc[df_encoded['tipo_renda'] == 'Pensionista', 'tempo_emprego'].fillna(-1)
    df_encoded.loc[df_encoded['tipo_renda'] == 'Pensionista', 'tempo_emprego'].value_counts()
    df_encoded['renda_log'] = np.log1p(df_encoded['renda'])
    ordem_escolaridade = ['Prim√°rio', 'Secund√°rio', 'Superior incompleto', 'Superior completo', 'P√≥s gradua√ß√£o']
    mapa_escolaridade = {nivel: i for i, nivel in enumerate(ordem_escolaridade)}
    df_encoded['educacao_ordinal'] = df_encoded['educacao'].map(mapa_escolaridade)
    df_encoded.drop(columns=['educacao', 'renda'], inplace=True)
    df_encoded = pd.get_dummies(df_encoded, drop_first=True, dtype=int)
    df_encoded.posse_de_imovel = df_encoded.posse_de_imovel.astype(int)
    df_encoded.posse_de_veiculo = df_encoded.posse_de_veiculo.astype(int)

    return df_encoded

@st.cache_data
def gerar_relatorio(_df):
    # Gerar relat√≥rio
    profile = ProfileReport(_df, title='An√°lise de Previs√£o de Renda')

    # Converter o relat√≥rio para HTML
    report_html_str = profile.to_html()
    soup = BeautifulSoup(report_html_str, 'html.parser')

    # Remover a barra de navega√ß√£o (A barra tem gerado problemas de renderiza√ß√£o no Streamlit)
    nav_bar = soup.find('nav')
    if nav_bar:
        nav_bar.decompose()

    for a_tag in soup.find_all('a'):
        if a_tag.has_attr('href') and a_tag['href'].startswith('#'):
            del a_tag['href']
        if a_tag.has_attr('target'):
            del a_tag['target']

    
    return str(soup)

def otimizar_random_forest(profundidades, folhas, X_train, X_test, y_train, y_test):
    r2s = []
    indicador_profundidade = []
    indicador_folha = []
    
    total_iterations = len(profundidades) * len(folhas)
    st.markdown('---')
    my_bar = st.progress(0, text="Otimiza√ß√£o em andamento... Por favor, aguarde.")
    iteration_count = 0

    for profundidade in profundidades:
        for folha in folhas:
            iteration_count += 1

            time.sleep(0.1)
            modelo = RandomForestRegressor(max_depth=profundidade, min_samples_leaf=folha, random_state=42)
            modelo.fit(X_train, y_train)
            r2 = modelo.score(X_test, y_test)
            
            r2s.append(r2)
            indicador_profundidade.append(profundidade)
            indicador_folha.append(folha)
            
            percent_complete = iteration_count / total_iterations
            my_bar.progress(percent_complete, text=f"Progresso: {iteration_count}/{total_iterations} combina√ß√µes testadas.")

    renda_r2 = pd.DataFrame({'r2': r2s, 'profundidade': indicador_profundidade, 'n_minimo': indicador_folha})
    sns.heatmap(renda_r2.pivot(index='profundidade',
                columns='n_minimo', values='r2'), vmin=.4)
    renda_r2.pivot(index='profundidade', columns='n_minimo', values='r2')

    melhor_r2 = 0
    pivot_df = renda_r2.pivot(index='profundidade', columns='n_minimo', values='r2')
    for folha in pivot_df.columns:
        for profundidade in pivot_df.index:
            if pivot_df.loc[profundidade, folha] > melhor_r2:
                melhor_folha, melhor_profundidade, melhor_r2 = folha, profundidade, pivot_df.loc[profundidade, folha]
                print(melhor_folha, melhor_profundidade, melhor_r2)

    return melhor_folha, melhor_profundidade, melhor_r2

def side_bar():
    # Barra lateral de navega√ß√£o
    st.markdown('# Previs√£o de renda')
    st.markdown('----')

    st.sidebar.title('Navega√ß√£o')

    sidebar = st.sidebar

    if sidebar.button('P√°gina Inicial üè†'):
        st.session_state.pagina_atual = 'view_home'
        st.rerun() # Opcional, mas garante uma transi√ß√£o imediata e limpa

    if sidebar.button('Etapa 1 - CRISP-DM: Entendimento do Neg√≥cio üîç'):
        st.session_state.pagina_atual = 'view_entendimento'
        st.rerun() # Opcional, mas garante uma transi√ß√£o imediata e limpa

    if sidebar.button('Etapa 2 - CRISP-DM: Entendimento dos Dados üîç'):
        st.session_state.pagina_atual = 'view_eda'
        st.rerun() # Opcional, mas garante uma transi√ß√£o imediata e limpa

    if sidebar.button('Etapa 3 Crisp-DM: Prepara√ß√£o dos dados üîç'):
        st.session_state.pagina_atual = 'view_preprocessamento'
        st.rerun() # Opcional, mas garante uma transi√ß√£o imediata e limpa

    if sidebar.button('Etapa 4 Crisp-DM: Modelagem üîç'):
        st.session_state.pagina_atual = 'view_modelagem'
        st.rerun() # Opcional, mas garante uma transi√ß√£o imediata e limpa

    if sidebar.button('Etapa 5 Crisp-DM: Avalia√ß√£o dos resultados üîç'):
        st.session_state.pagina_atual = 'view_conclusao'
        st.rerun() # Opcional, mas garante uma transi√ß√£o imediata e limpa
def rodape():
    # Rodap√©
    st.markdown('----')
    st.markdown('Projeto desenvolvido por Antonio Moura Jr. | [LinkedIn](https://www.linkedin.com/in/antoniomourajr/) | [GitHub](https://github.com/0ace-jk/) | [Kaggle](https://www.kaggle.com/antoniojunior1998)')


def view_home():
    # P√°gina inicial
    side_bar()
    st.title('Meu Projeto de An√°lise de Renda: Uma Jornada com Dados üöÄ')

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, 1])
    col_texto_b.markdown(
        """
        Ol√°! Seja bem-vindo(a) √† apresenta√ß√£o do meu projeto de an√°lise de dados. Esta aplica√ß√£o foi criada para demonstrar, de forma interativa, todas as etapas de uma investiga√ß√£o sobre a previs√£o de renda utilizando uma base de dados real.

        Neste projeto, meu objetivo foi mergulhar em um conjunto de dados para descobrir padr√µes, testar hip√≥teses e construir um modelo de Machine Learning funcional. Todo o processo foi guiado pela metodologia CRISP-DM, um framework que ajuda a organizar o racioc√≠nio e as tarefas em um projeto de dados.

        Esta aplica√ß√£o √© dividida nas fases do CRISP-DM. Convido voc√™ a navegar pelas se√ß√µes usando o menu lateral:

        - Comece pelo Entendimento do Neg√≥cio: Para entender o "porqu√™" deste projeto.

        - Mergulhe no Entendimento dos Dados: Onde voc√™ encontrar√° uma an√°lise explorat√≥ria completa e interativa.

        - Acompanhe a Prepara√ß√£o dos Dados: Veja como os dados brutos foram transformados e preparados para a modelagem.

        - Descubra a Modelagem: Conhe√ßa os modelos que treinei e seus fundamentos.

        - Confira a Avalia√ß√£o: Veja se os modelos performaram bem e se atingimos nossos objetivos.
        """
    )

    st.markdown('----')
    st.markdown('## Como me encontrar:')
    col_perfil_a, col_perfil_b, col_perfil_c = st.columns([10, 1, 1])
    col_perfil_a.link_button('LinkedIn', url=('https://www.linkedin.com/in/antoniomourajr/'))
    col_perfil_a.link_button('GitHub', url=('https://github.com/0ace-jk/'))
    col_perfil_a.link_button('Kaggle', url=('https://www.kaggle.com/antoniojunior1998'))


def view_entendimento():
    # P√°gina de entendimento do neg√≥cio
    side_bar()
    st.title('Etapa 1 - CRISP-DM: Entendimento do Neg√≥cio')
    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])
    col_texto_b.write(
        """
        A primeira etapa do **CRISP-DM (Cross Industry Standard Process for Data Mining)** √© dedicada ao **entendimento do neg√≥cio**.  
        Antes de qualquer an√°lise ou modelagem, √© fundamental compreender o contexto do problema, os objetivos estrat√©gicos da organiza√ß√£o e como a solu√ß√£o baseada em dados poder√° gerar valor.

        No nosso caso, estamos trabalhando com uma **base de dados de clientes de uma institui√ß√£o financeira**.  
        O objetivo principal √© **desenvolver um modelo preditivo capaz de estimar, com a maior precis√£o e consist√™ncia poss√≠vel, o valor da vari√°vel *"renda"* de cada cliente**.  

        Essa previs√£o √© relevante para a institui√ß√£o, pois auxilia em processos como:  
        - Avalia√ß√£o de cr√©dito e defini√ß√£o de limites;  
        - An√°lise de risco financeiro;  
        - Segmenta√ß√£o de clientes para produtos e servi√ßos;  
        - Suporte a decis√µes estrat√©gicas relacionadas √† concess√£o de empr√©stimos e investimentos.  

        Com um bom entendimento do neg√≥cio, podemos alinhar expectativas, definir m√©tricas de sucesso e garantir que os resultados obtidos no final do processo atendam √†s necessidades reais da institui√ß√£o.
        """
    )

    rodape()


def view_eda():
    # P√°gina de entendimento dos dados
    side_bar()
    st.title('Etapa 2 - CRISP-DM: Entendimento dos Dados')

    # Carrega os dados usando a fun√ß√£o em cache
    df_dados = carregar_dados()

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])

    col_texto_b.markdown(
        """
        Ap√≥s compreender o problema de neg√≥cio, o pr√≥ximo passo do processo **CRISP-DM** √© o **entendimento dos dados**.  
        Nessa etapa, buscamos conhecer a fundo a base dispon√≠vel, explorando suas caracter√≠sticas, qualidade e limita√ß√µes.  

        O objetivo √© responder perguntas como:  
        - Quais informa√ß√µes est√£o dispon√≠veis na base?  
        - Qual a qualidade desses dados (existem valores ausentes, inconsist√™ncias ou outliers)?  
        - Existem vari√°veis irrelevantes ou redundantes?  
        - Quais rela√ß√µes iniciais podem ser observadas entre as vari√°veis e a vari√°vel-alvo (*renda*)?  

        ### Contexto da Base de Dados
        A base utilizada corresponde a informa√ß√µes de **clientes de uma institui√ß√£o financeira**, contendo vari√°veis demogr√°ficas, socioecon√¥micas e relacionadas ao perfil de consumo.  

        Essa etapa √© essencial para:  
        - Garantir que os dados estejam em condi√ß√µes adequadas para an√°lise;  
        - Identificar poss√≠veis ajustes e transforma√ß√µes necess√°rias na etapa de **Prepara√ß√£o dos Dados**;  
        - Levantar hip√≥teses iniciais que poder√£o ser confirmadas ou rejeitadas nas an√°lises posteriores.  

        Em resumo, o entendimento dos dados funciona como um diagn√≥stico inicial, que guiar√° a prepara√ß√£o e a modelagem, assegurando que o modelo preditivo seja constru√≠do sobre uma base confi√°vel e representativa.
        """
    )

    col_analyse_a, col_analyse_b = st.columns([1, 1])

    st.markdown(
        '''
        | Vari√°vel                | Descri√ß√£o                                                   | Tipo                                              |
        | ----------------------- |:-----------------------------------------------------------:| -------------------------------------------------:|
        | data_ref                |  Data de Refer√™ncia                                         | <span style="color:red">Objeto (str)</span>       |
        | id_cliente              |  Id do cliente                                              | <span style="color:red">Inteiro</span>            |
        | sexo                    |  Sexo do cliente **M** = Masculino **F** = Feminino         | <span style="color:red">Objeto (str)</span>       |
        | posse_de_veiculo        |  Cliente tem veiculo? **True** = Sim, **False** = N√£o       | <span style="color:red">Booleano</span>           |
        | posse_de_imovel         |  Cliente tem imovel? **True** = Sim, **False** = N√£o        | <span style="color:red">Booleano</span>           |
        | qtd_filhos              |  Quantidade de filhos                                       | <span style="color:red">Inteiro</span>            |
        | tipo_renda              |  Tipo de renda. (Assalariado, Empres√°rio, etc)              | <span style="color:red">Objeto (str)</span>       |
        | educacao                |  Tipo de educa√ß√£o que o cliente completou                   | <span style="color:red">Objeto (str)</span>       |
        | estado_civil            |  Estado civil. (Casado, Solteiro, etc)                      | <span style="color:red">Objeto (str)</span>       |
        | tipo_residencia         |  Tipo de resid√™ncia. (Casa, Aluguel, etc)                   | <span style="color:red">Objeto (str)</span>       |
        | idade                   |  Idade do cliente                                           | <span style="color:red">Inteiro</span>            |
        | tempo_emprego           |  Tempo em que o cliente est√° empregado                      | <span style="color:red">Ponto Flutuante</span>    |
        | qt_pessoas_residencia   |  Quantidade de pessoas que vivem na resid√™ncia do cliente   | <span style="color:red">Ponto Flutuante</span>    |
        | renda                   |  Valor da renda                                             | <span style="color:red">Ponto Flutuante</span>    |
        ''', unsafe_allow_html=True
    )

    st.markdown('---')
    st.markdown('### Entendimento dos dados - Univariada')
    # Gera o relat√≥rio HTML usando a nova fun√ß√£o em cache
    html_relatorio = gerar_relatorio(df_dados.copy())
    # Exibe o HTML final no Streamlit
    st.components.v1.html(html_relatorio, height=800, scrolling=True)

    st.markdown('---')

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])
    col_texto_b.markdown(
        '''
        ### Observamos alguns pontos interessantes, como os valores faltantes da vari√°vel *'tempo_emprego'* ter uma quantidade grande de **missing values** porem, ao crusarmos esses dados com a vari√°vel *'tipo_renda'* observamos que esses valores faltantes s√£o predominantemente de pensionistas.

        #### Mas por que pensionistas tem dados faltantes em tempo de emprego? Vamos entender.

        - Pensionistas apresentam tempo de emprego igual a zero nos dados porque, geralmente, o sistema de registos considera que um pensionista n√£o est√° em atividade de emprego, sendo o tempo de trabalho j√° encerrado e focado no recebimento de uma pens√£o.
        - Em resumo, o pensionista recebe um benef√≠cio que substitui a remunera√ß√£o, e n√£o um sal√°rio, logo o registo de tempo de emprego √© nulo, pois n√£o h√° atividade laboral.

        '''
    )

    st.markdown('---')
    st.markdown('# Entendimento dos dados - Bivariada')

    corr = df_dados.corr(numeric_only=True)
    corr

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])

    col_texto_b.markdown(
        '''
        Com uma simples tabela de correla√ß√£o conseguimos observar alguns detalhes importantes de rela√ß√µes que temos em nossos dados.

        Na tabela, comparamos cada variavel entre elas, o valor <span style="color:red">**[1]**</span> significa que as variaveis comparadas tem uma rela√ß√£o muito forte, se o valor for <span style="color:red">**[0]**</span>, significa que elas n√£o tem nenhuma rela√ß√£o, e se o valor for <span style="color:red">**[-1]**</span> significa que elas tem uma rela√ß√£o inversa muito forte!
        - *Quantidade de pessoas na resid√™ncia* se relaciona muito com a *quantidade de filhos*, o que faz total sentido.
        - A *Idade* tem uma grande correla√ß√£o com o *Tempo de emprego*, mais uma correla√ß√£o forte esperada.

        Mas estamos buscando entender a vari√°vel *Renda*, entao vamos analisar ela mais de perto.
        - O *Tempo de emprego* e *Posse de ve√≠culo* possuem uma maior correla√ß√£o com a renda, pelo menos a primeira vista.

        Vamos observar como elas se comportam.
        ''', unsafe_allow_html=True
    )

    container = st.container()

    col_chart_a, col_chart_b = container.columns([.5, .5], border=True)

    col_chart_a.markdown('#### (Amostra de 250 indiv√≠duos)')

    col_chart_b.markdown('#### (15000 indiv√≠duos)')

    col_chart_a.scatter_chart(df_dados.sample(n=250), y='tempo_emprego', x='renda', color='posse_de_veiculo', x_label='Renda', y_label='Tempo de emprego')

    sns.set_theme(style='ticks')
    sns.jointplot(data=df_dados, x='renda', y='tempo_emprego', hue='posse_de_veiculo')
    col_chart_b.pyplot(plt)
    plt.close()

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])

    col_texto_b.markdown(
        '''
        ---

        Mesmo com um grafico de dispers√£o fica dificil observar essa correla√ß√£o.

        Est√° n√≠tido a necessidade de prepara√ß√£o desses dados para conseguirmos visualizar com clareza.
        '''
    )

    rodape()


def view_preprocessamento():
    # P√°gina de entendimento dos dados
    side_bar()
    st.title('Etapa 3 Crisp-DM: Prepara√ß√£o dos dados')

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])

    col_texto_b.markdown(
        '''
        Nessa etapa realizamos tipicamente as seguintes opera√ß√µes com os dados:

        - **sele√ß√£o**: J√° temos os dados selecionados adequadamente?
        - **limpeza**: Precisaremos identificar e tratar dados faltantes
        - **constru√ß√£o**: constru√ß√£o de novas vari√°veis
        - **integra√ß√£o**: Temos apenas uma fonte de dados, n√£o √© necess√°rio integra√ß√£o
        - **formata√ß√£o**: Os dados j√° se encontram em formatos √∫teis?


        '''
    )

    st.markdown(
        '''
        Vamos rever os dados que temos.

        Coluna | Tipo de dado | Obs
        :------|:------------:|:-----
        Unnamed: 0 | int64 | Essa coluna √© apenas o index dos dados, vamos retirar do nosso modelo pois ela n√£o agregar√° em nada.
        data_ref | object | A data √© algo importante ao analisar s√©ries temporais, por√©m, esse n√£o √© nosso objetivo com esse modelo, vamos retirar ela tbm.
        id_cliente | int64 | Como a coluna de index, esse id do cliente n√£o ser√° necessario, vamos retira-lo tamb√©m.
        sexo | object | Uma vari√°vel com F e M, como boa pratica, vamos atribuir um 1 para Feminino e 0 para Masculino para nosso modelo entender de maneira correta essa vari√°vel.
        posse_de_veiculo | bool | Um booleano, sem problemas, mas como uma boa pratica, vamos atribuir valores com 0 e 1.
        posse_de_imovel | bool | Mesma situa√ß√£o da posse_de_veiculo, vamos atribuir valores com 0 e 1.
        qtd_filhos | int64 | Tudo certo com essa variavel.
        tipo_renda | object | Uma vari√°vel qualitativa nominal, vamos usar o One-Hot Encoding(Dummies).
        educacao | object | Uma vari√°vel qualitativa ordinal, aqui vamos usar uma t√©cnica diferente e mais eficiente para nosso modelo, Codifica√ß√£o ordinal.
        estado_civil | object | Uma vari√°vel qualitativa nominal, vamos usar o One-Hot Encoding(Dummies).
        tipo_residencia | object | Uma vari√°vel qualitativa nominal, vamos usar o One-Hot Encoding(Dummies).
        idade | int64 | Tudo certo com a idade, n√£o poss√∫i outliers, vamos manter ela como est√°.
        tempo_emprego | float64 | Aparentemente tudo correto por aqui, detalhe de alguns valores faltantes como discutido anteriormente.
        qt_pessoas_residencia | float64 | Tudo certo por aqui tamb√©m.
        renda | float64 | Nossa vari√°vel alvo, vamos aplicar uma t√©cnica nela e em outras vari√°veis para "Normalizar" essas curvas muitos acentuadas.
        '''
    )

    st.markdown('---')

    df = carregar_dados()

    st.markdown('### Dados brutos')
    st.markdown('Abaixo temos uma amostra dos dados brutos da renda, antes de qualquer pr√©-processamento.')

    sns.set_theme('notebook')
    sns.histplot(df, x='renda', kde=True)
    st.pyplot(plt)
    plt.close()

    st.markdown(
        '''
        Veja que a curva de renda √© muito inclinada, com muitos dados concentrados em rendas mais baixas e uma cauda longa de rendas mais altas.
        '''
    )
    st.markdown('---')

    df_encoded = preprocessar_dados(df)

    st.markdown('### Dados pr√©-processados')
    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])
    col_texto_b.markdown('Abaixo temos uma amostra dos dados j√° pr√©-processados, prontos para serem usados em um modelo de Machine Learning.')
    st.dataframe(df_encoded.head(10))

    st.markdown('#### Aplicamos o log na vari√°vel renda para "normalizar" a curva, deixando-a mais pr√≥xima de uma distribui√ß√£o normal.')

    sns.set_theme('notebook')
    sns.histplot(df_encoded, x='renda_log', kde=True)
    st.pyplot(plt)

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])
    col_texto_b.markdown(
        '''
        ### Para saber exatamente como tudo foi pr√©-processado, veja o notebook [projeto-2.ipynb](https://github.com/0ace-jk/previsao_renda/blob/main/projeto-2.ipynb)  no GitHub.
        '''
    )

    rodape()


def view_modelagem():
    # P√°gina de entendimento dos dados
    side_bar()
    st.title('Etapa 4 Crisp-DM: Modelagem')

    col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1]) 

    col_texto_b.markdown(
        '''
        Nessa etapa que realizaremos a constru√ß√£o do modelo. Os passos t√≠picos s√£o:
        - Selecionar a t√©cnica de modelagem
        - Desenho do teste
        - Avalia√ß√£o do modelo
        '''
    )

    col_texto_b.markdown(
        '''
        Vamos separar nossa base de testes entre variaveis independentes, ***X***, e variavel alvo ***y***

        Nossa base possui 15.000 registros.
        Optamos por utilizar 80% dos dados para treino (12.000 registros) e 20% para teste (3.000 registros).

        Essa divis√£o garante que o modelo tenha dados suficientes para aprender e, ao mesmo tempo, que possamos avaliar seu desempenho em situa√ß√µes novas, simulando cen√°rios reais.

        ---

        ### Execu√ß√£o (Treinamento) do Modelo

        Nesta etapa, ensinamos o modelo de Machine Learning a reconhecer padr√µes nos dados.

        - O algoritmo Random Forest cria diversas √°rvores de decis√£o, cada uma aprendendo padr√µes diferentes da base.

        - Essas √°rvores s√£o combinadas para gerar um resultado final mais robusto e confi√°vel (da√≠ o nome floresta aleat√≥ria).

        Em resumo: executar o modelo significa treinar a Random Forest para entender o comportamento dos clientes a partir do hist√≥rico fornecido.
        '''
    )

    df_encoded = preprocessar_dados(carregar_dados())
    X = df_encoded.drop(columns=['renda_log'], axis=1).copy()
    y = df_encoded['renda_log'].copy()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=4)

    st.markdown(
        '''
        ---

        Com o bot√£o abaixo, voc√™ pode iniciar o processo de otimiza√ß√£o do modelo RandomForest, que ajusta os hiperpar√¢metros para melhorar a performance do modelo.
        '''
    )

    st.markdown('<p style="color:red;">A otimiza√ß√£o pode levar v√°rios minutos, tenha em mente que essa etapa pode ser demorada.</p>', unsafe_allow_html=True)
    

    if st.button("Iniciar Otimiza√ß√£o do RandomForest"):

        melhor_folha_1, melhor_profundidade_1, melhor_r2_1 = otimizar_random_forest(range(1, 92, 10), range(1, 92, 10), X_train, X_test, y_train, y_test)

        melhor_folha_2, melhor_profundidade_2, melhor_r2_2 = otimizar_random_forest(range(max(melhor_profundidade_1-11, 0)+1, melhor_profundidade_1+11, 3), range (max(melhor_folha_1-11, 0)+1, melhor_folha_1+11, 3), X_train, X_test, y_train, y_test)

        melhor_folha_3, melhor_profundidade_3, melhor_r2_3 = otimizar_random_forest(range(max(melhor_profundidade_2-3, 0)+1, melhor_profundidade_2+4), range (max(melhor_folha_2-3, 0)+1, melhor_folha_2+4), X_train, X_test, y_train, y_test)

        col_texto_a, col_texto_b, col_texto_c = st.columns([.1, 3, .1])
        st.markdown('---')
        st.markdown(f'Com isso consigo o melhor resultado para o min_sample_leaf, e para o max_depth.')
        st.markdown(f'- min_sample_leaf = **{melhor_folha_3}**')
        st.markdown(f'- max_depth = **{melhor_profundidade_3}**')



    rodape()


def view_conclusao():
    side_bar()
    st.title('Etapa 5 Crisp-DM: Avalia√ß√£o dos resultados')

    st.markdown(
        '''
        O cross_val_score do scikit-learn √© usado para rodar a valida√ß√£o cruzada do modelo ‚Äî ou seja, treinar e avaliar v√°rias vezes em diferentes divis√µes dos dados, obtendo uma m√©dia mais confi√°vel do desempenho.

        Esse ser√° o nosso m√©todo de avalia√ß√£o final do modelo.
        '''
    )

    st.markdown('---')
    st.markdown('Para n√£o ser necess√°rio rodar novamente a otimiza√ß√£o do RandomForest, j√° que o melhor resultado foi obtido, vamos treinar o modelo com esses hiperpar√¢metros e avaliar ele com o cross_val_score.')
    st.markdown('Relembrando os melhores hiperpar√¢metros encontrados: min_samples_leaf = 1 e max_depth = 15.')

    df_encoded = preprocessar_dados(carregar_dados())
    X = df_encoded.drop(columns=['renda_log'], axis=1).copy()
    y = df_encoded['renda_log'].copy()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=4)

    modelo = RandomForestRegressor(max_depth=15, min_samples_leaf=1, random_state=4)
    modelo.fit(X_train, y_train)

    r2_modelo = modelo.score(X_test, y_test)
    st.write(f'O R¬≤ do modelo alcan√ßado foi de: {r2_modelo:.4f}')



    scores = cross_val_score(modelo, X, y, cv=5, scoring="r2")
    st.write(f'R¬≤ em cada fold: ')
    col_a, col_b = st.columns([.3, .7])
    col_a.write(scores)
    st.write(f'\nR¬≤ m√©dio: ', scores.mean())
    st.write(f'Desvio padr√£o: ', scores.std())

    rodape()





if 'pagina_atual' not in st.session_state:
    st.session_state.pagina_atual = 'view_home'
if st.session_state.pagina_atual == 'view_home':
    view_home()
elif st.session_state.pagina_atual == 'view_entendimento':
    view_entendimento()
elif st.session_state.pagina_atual == 'view_eda':
    view_eda()
elif st.session_state.pagina_atual == 'view_preprocessamento':
    view_preprocessamento()
elif st.session_state.pagina_atual == 'view_modelagem':
    view_modelagem()
elif st.session_state.pagina_atual == 'view_conclusao':
    view_conclusao()
